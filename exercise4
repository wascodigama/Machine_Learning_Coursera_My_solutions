Neural Networks Learning

% Load saved matrices from file
load('ex4weights.mat');
% The matrices Theta1 and Theta2 will now be in your workspace
% Theta1 has size 25 x 401
% Theta2 has size 10 x 26


sigmoidGradient.m
g = sigmoid(z).*(1-sigmoid(z));


nnCostFuntion.m
%function [J grad] = nnCostFunction(nn_params, ...
%                                   input_layer_size, ...
%                                   hidden_layer_size, ...
%                                   num_labels, ...
%                                   X, y, lambda)
%Part 1: Feedforward the neural network and return the cost in the
%         variable J. After implementing Part 1, you can verify that your
%         cost function computation is correct by verifying the cost
%         computed in ex4.m
X = [ones(m,1) X]; %adding bias term
a1 = X;
z1 = a1*Theta1'; %first hidden layer input

a2 = sigmoid(z1); %first hidden layer output 
a2 = [ones(size(a2),1) a2]; %adding bias term
z2 = a2*Theta2'; %second hidden layer's input
h_x = sigmoid(z2); %output features
yv = (1:num_labels)==y; %labeling features
J = (1/m)*sum(sum((-yv.*log(h_x))-((1-yv).*log(1-h_x)))); % simple feed forward costfuntion

Part 2: Implement the backpropagation algorithm to compute the gradients
%         Theta1_grad and Theta2_grad. You should return the partial derivatives of
%         the cost function with respect to Theta1 and Theta2 in Theta1_grad and
%         Theta2_grad, respectively. After implementing Part 2, you can check
%         that your implementation is correct by running checkNNGradients
%
%         Note: The vector y passed into the function is a vector of labels
%               containing values from 1..K. You need to map this vector into a 
%               binary vector of 1's and 0's to be used with the neural network
%               cost function.
%
%         Hint: We recommend implementing backpropagation using a for-loop
%               over the training examples if you are implementing it for the 
%               first time.
%
% Part 3: Implement regularization with the cost function and gradients.
%
%         Hint: You can implement this around the code for
%               backpropagation. That is, you can compute the gradients for
%               the regularization separately and then add them to Theta1_grad
%               and Theta2_grad from Part 2.
reg_t = (lambda/(2*m))*(sum(sum(Theta1(:,2:end).^2)) + sum(sum(Theta2(:,2:end).^2))); %regularization term
J = J + reg_t;

%backpropogation
for i = 1:m
a1 = X(i,:)'; %first hidden layer
z1 = Theta1*a1;

a2 = [1; sigmoid(z1)]; %second hidden layer
z2 = Theta2*a2;

h_x = sigmoid(z2);
yvec = (1:num_labels)' == y(i);
delta3 = h_x - yvec;
delta2 = (Theta2'*delta3).*[1; sigmoidGradient(z1)];
delta2 = delta2(2:end);

Theta1_grad = Theta1_grad + (delta2*a1');
Theta2_grad = Theta2_grad + (delta3*a2');
end

%gradient
Theta1_grad = (1/m)*Theta1_grad;
Theta2_grad = (1/m)*Theta2_grad;

grad_t1 = (lambda/m)*[zeros(size(Theta1,1),1), Theta1(:,2:end)];
grad_t2 = (lambda/m)*[zeros(size(Theta2,1),1), Theta2(:,2:end)];

Theta1_grad = Theta1_grad + grad_t1;
Theta2_grad = Theta2_grad + grad_t2;
% =========================================================================


randInitializeWeights.m
% Randomly initialize the weights to small values
epsilon init = 0.12;
W = rand(L out, 1 + L in) * 2 * epsilon init ô€€€ epsilon init;


